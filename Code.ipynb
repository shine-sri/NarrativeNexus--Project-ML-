{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03885da3-8e97-4bfa-b85a-949583e571cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(74553) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pathway sentence-transformers faiss-cpu pandas numpy tqdm ollama scikit-learn\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24f6ca-cffa-4a3f-b91b-cdc1718b2f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Global and Local Indices...\n",
      "Extracting Training Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 12/12 [11:08<00:00, 55.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL SYSTEM ACCURACY: 0.7500\n",
      "Generating Submission...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████▍                     | 24/60 [2:03:02<18:31:12, 1852.00s/it]"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# KDSH 2026 — ULTIMATE ROBUST HYBRID PIPELINE\n",
    "# Pathway + Dual-RAG + ML + CoT reasoning\n",
    "# ============================================================\n",
    "\n",
    "import os, re, glob, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import faiss\n",
    "import ollama\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "OLLAMA_MODEL = \"phi3:latest\" \n",
    "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
    "RAG_K = 15\n",
    "MIN_SIM_FOR_LLM = 0.22  # Trigger reasoning for even moderate matches\n",
    "MIN_PAR_LEN = 20\n",
    "\n",
    "embedder = SentenceTransformer(EMBED_MODEL)\n",
    "\n",
    "# ============================================================\n",
    "# ADVANCED MAPPING & DOSSIER BUILDING\n",
    "# ============================================================\n",
    "def clean_text(t):\n",
    "    t = str(t)\n",
    "    t = t.replace(\"“\", '\"').replace(\"”\", '\"').replace(\"’\", \"'\")\n",
    "    return re.sub(r\"\\s+\", \" \", t).strip()\n",
    "\n",
    "def canon_char(name): return re.sub(r\"\\s+\", \" \", str(name).lower().strip())\n",
    "def canon_book(name): return name.lower().replace(\".txt\", \"\").strip()\n",
    "\n",
    "def get_alias_regex(char):\n",
    "    parts = char.split()\n",
    "    aliases = {char}\n",
    "    if len(parts) >= 2:\n",
    "        aliases.add(parts[-1])\n",
    "        for t in [\"mr\", \"mrs\", \"miss\", \"sir\", \"ms\", \"count\"]:\n",
    "            aliases.add(f\"{t} {parts[-1]}\")\n",
    "    return r\"|\".join([rf\"\\b{re.escape(a)}\\b\" for a in aliases])\n",
    "\n",
    "# ============================================================\n",
    "# DUAL-INDEX RAG (LOCAL + GLOBAL)\n",
    "# ============================================================\n",
    "FAISS_LOCAL = {}\n",
    "FAISS_GLOBAL = {}\n",
    "\n",
    "def build_indices(train_df, test_df):\n",
    "    required_chars = defaultdict(set)\n",
    "    for df in [train_df, test_df]:\n",
    "        for r in df.itertuples():\n",
    "            required_chars[canon_book(r.book_name)].add(canon_char(r.char))\n",
    "\n",
    "    for path in glob.glob(\"*.txt\"):\n",
    "        book_key = canon_book(path)\n",
    "        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            text = f.read()\n",
    "            if \"*** START\" in text: text = text.split(\"*** START\", 1)[1]\n",
    "            if \"*** END\" in text: text = text.split(\"*** END\", 1)[0]\n",
    "            \n",
    "            paras = [clean_text(p) for p in text.split(\"\\n\\n\") if len(p) > MIN_PAR_LEN]\n",
    "            if not paras: continue\n",
    "            \n",
    "            # 1. Global Index (Safety Net)\n",
    "            g_emb = embedder.encode(paras, normalize_embeddings=True)\n",
    "            g_idx = faiss.IndexFlatIP(g_emb.shape[1])\n",
    "            g_idx.add(g_emb)\n",
    "            FAISS_GLOBAL[book_key] = (g_idx, paras)\n",
    "            \n",
    "            # 2. Local Mapping (Character specific with windows)\n",
    "            book_chars = required_chars.get(book_key, set())\n",
    "            for char in book_chars:\n",
    "                regex = re.compile(get_alias_regex(char), re.I)\n",
    "                char_paras = []\n",
    "                for i, p in enumerate(paras):\n",
    "                    if regex.search(p):\n",
    "                        # Add window context (i-1, i, i+1)\n",
    "                        window = \" \".join(paras[max(0, i-1):min(len(paras), i+2)])\n",
    "                        char_paras.append(window)\n",
    "                \n",
    "                if char_paras:\n",
    "                    char_paras = list(set(char_paras))\n",
    "                    l_emb = embedder.encode(char_paras, normalize_embeddings=True)\n",
    "                    l_idx = faiss.IndexFlatIP(l_emb.shape[1])\n",
    "                    l_idx.add(l_emb)\n",
    "                    FAISS_LOCAL[f\"{book_key}::{char}\"] = (l_idx, char_paras)\n",
    "\n",
    "def hybrid_retrieve(book, char, query, k=RAG_K):\n",
    "    book, char = canon_book(book), canon_char(char)\n",
    "    res = []\n",
    "    \n",
    "    # Check Local First\n",
    "    local_key = f\"{book}::{char}\"\n",
    "    if local_key in FAISS_LOCAL:\n",
    "        idx, paras = FAISS_LOCAL[local_key]\n",
    "        q_emb = embedder.encode([query], normalize_embeddings=True)\n",
    "        s, ids = idx.search(q_emb, min(k, len(paras)))\n",
    "        res = [(paras[i], float(s[0][j])) for j, i in enumerate(ids[0])]\n",
    "    \n",
    "    # If weak results, fall back to Global\n",
    "    if not res or res[0][1] < 0.30:\n",
    "        if book in FAISS_GLOBAL:\n",
    "            idx, paras = FAISS_GLOBAL[book]\n",
    "            q_emb = embedder.encode([query], normalize_embeddings=True)\n",
    "            s, ids = idx.search(q_emb, k)\n",
    "            res = list(set(res + [(paras[i], float(s[0][j])) for j, i in enumerate(ids[0])]))\n",
    "            res = sorted(res, key=lambda x: x[1], reverse=True)[:k]\n",
    "    return res\n",
    "\n",
    "# ============================================================\n",
    "# ML FEATURES\n",
    "# ============================================================\n",
    "def extract_features(ret, query):\n",
    "    if not ret: return [0.0] * 6\n",
    "    scores = [s for _, s in ret]\n",
    "    return [max(scores), np.mean(scores), np.std(scores), np.percentile(scores, 75), len(ret), scores[0] - scores[-1]]\n",
    "\n",
    "# ============================================================\n",
    "# ROBUST CoT OLLAMA JUDGE\n",
    "# ============================================================\n",
    "def ollama_judge_robust(book, query, evidence):\n",
    "    ev_text = \"\\n\".join([f\"SCENE {i}: {p}\" for i, (p, _) in enumerate(evidence[:6])])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Act as a Senior Continuity Editor. Your task is to find FACTUAL CONTRADICTIONS.\n",
    "\n",
    "CLAIM TO TEST: \"{query}\"\n",
    "BOOK CONTEXT: {book}\n",
    "\n",
    "EVIDENCE FROM TEXT:\n",
    "{ev_text}\n",
    "\n",
    "THOUGHT PROCESS:\n",
    "1. What is the specific fact asserted in the CLAIM? (e.g., Character X is dead, or Character Y is at location Z)\n",
    "2. Does the EVIDENCE mention this fact?\n",
    "3. Is there a direct contradiction? (Example: Claim says \"Married\", Evidence says \"Single\"). \n",
    "4. Note: If the evidence is just about a different topic, it is CONSISTENT (1).\n",
    "\n",
    "Return JSON ONLY:\n",
    "{{\n",
    "  \"analysis\": \"Identify specific scenes that contradict or support.\",\n",
    "  \"verdict\": 0 or 1\n",
    "}}\n",
    "0 = CONTRADICT, 1 = CONSISTENT\n",
    "\"\"\"\n",
    "    try:\n",
    "        r = ollama.chat(model=OLLAMA_MODEL, messages=[{\"role\": \"user\", \"content\": prompt}], options={\"temperature\": 0})\n",
    "        content = r[\"message\"][\"content\"]\n",
    "        match = re.search(r\"\\{.*\\}\", content, re.DOTALL)\n",
    "        if match:\n",
    "            res = json.loads(match.group(0))\n",
    "            return int(res.get(\"verdict\", 1))\n",
    "    except:\n",
    "        pass\n",
    "    return 1 # Default to Consistent (Safe bet in literature)\n",
    "\n",
    "# ============================================================\n",
    "# EXECUTION PIPELINE\n",
    "# ============================================================\n",
    "def main():\n",
    "    # 1. Load Data\n",
    "    train_df = pd.read_csv(\"train.csv\")\n",
    "    test_df = pd.read_csv(\"test.csv\")\n",
    "    \n",
    "    def prep(df):\n",
    "        df[\"Full_Query\"] = df.apply(lambda r: clean_text(f\"{r['caption']} : {r['content']}\") if pd.notna(r['caption']) else clean_text(r['content']), axis=1)\n",
    "        if \"label\" in df.columns:\n",
    "            df[\"label\"] = df[\"label\"].str.lower().map({\"consistent\": 1, \"contradict\": 0})\n",
    "        return df\n",
    "\n",
    "    train_df = prep(train_df)\n",
    "    test_df = prep(test_df)\n",
    "\n",
    "    # 2. Indexing\n",
    "    print(\"Building Global and Local Indices...\")\n",
    "    build_indices(train_df, test_df)\n",
    "\n",
    "    # 3. ML Training\n",
    "    print(\"Extracting Training Features...\")\n",
    "    X = [extract_features(hybrid_retrieve(r.book_name, r.char, r.Full_Query), r.Full_Query) for r in train_df.itertuples()]\n",
    "    y = train_df[\"label\"].values\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=1000, max_depth=12, class_weight=\"balanced\", random_state=42).fit(X_tr, y_tr)\n",
    "\n",
    "    # 4. Hybrid Inference\n",
    "    def run_inference(df_subset):\n",
    "        results = []\n",
    "        for r in tqdm(df_subset.itertuples(), total=len(df_subset)):\n",
    "            ret = hybrid_retrieve(r.book_name, r.char, r.Full_Query)\n",
    "            feats = extract_features(ret, r.Full_Query)\n",
    "            ml_prob = rf.predict_proba([feats])[0][1] # Prob(Consistent)\n",
    "            \n",
    "            # Logic: If evidence found, let CoT verify.\n",
    "            if ret and feats[0] > MIN_SIM_FOR_LLM:\n",
    "                llm_verdict = ollama_judge_robust(r.book_name, r.Full_Query, ret)\n",
    "                \n",
    "                # Confidence-Weighted Verdict\n",
    "                if llm_verdict == 0:\n",
    "                    final = 0 if ml_prob < 0.75 else 1 # High bar for LLM contradiction\n",
    "                else:\n",
    "                    final = 1 if ml_prob > 0.30 else 0\n",
    "            else:\n",
    "                final = 1 if ml_prob > 0.45 else 0\n",
    "            results.append(final)\n",
    "        return results\n",
    "\n",
    "    # 5. Validation\n",
    "    val_indices = train_df.index[len(X_tr):]\n",
    "    val_preds = run_inference(train_df.iloc[val_indices])\n",
    "    acc = (np.array(val_preds) == y_val).mean()\n",
    "    print(f\"\\nFINAL SYSTEM ACCURACY: {acc:.4f}\")\n",
    "\n",
    "    # 6. Test/Submission\n",
    "    print(\"Generating Submission...\")\n",
    "    test_preds = run_inference(test_df)\n",
    "    test_df[\"prediction\"] = [\"consistent\" if p == 1 else \"contradict\" for p in test_preds]\n",
    "    test_df[[\"id\", \"prediction\"]].to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457e6fd6-3c1c-4e82-af6d-d1059fea899c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b0487d-ad0f-44bf-b544-6dc72b25c244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
